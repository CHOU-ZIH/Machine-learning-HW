{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GCBAMnet-r2-CBAM1-256.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1MjFDoENvVZnpOSaYgF0jxAm3-RfolEcn","authorship_tag":"ABX9TyNOJZ/6gMcxPwNDL0eU+i5n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nktdswoSjaAz"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.layers import Conv2D, concatenate, BatchNormalization, DepthwiseConv2D\n","from tensorflow.keras.layers import Lambda, Reshape, Layer, Activation, Add, Multiply\n","from tensorflow.keras import layers\n","from math import ceil\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDukHV149z9r"},"source":["class AE(Model):\n","  def __init__(self):\n","    super(AE, self).__init__()\n","    self.code = Dense(8,activation = 'relu')\n","  def build(self, input_shape):\n","    self.dense1 = Dense(input_shape[-1], activation = 'relu')\n","    self.dense2 = Dense(input_shape[-1], activation = 'relu')\n","  def call(self, inputs):    \n","    d1 = self.dense1(inputs)\n","    code = self.code(d1)\n","    d2 = self.dense2(code)    \n","    return d2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEIzitAPzu5S"},"source":["class CBAM(Model):\n","  def __init__(self):\n","    super(CBAM, self).__init__()          \n","    self.relu = Activation('relu') \n","    self.AvgPool = AveragePooling2D(pool_size=(2, 2),strides=(1, 1), padding='same')\n","    self.MaxPool = MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='same')    \n","    self.conv = Conv2D(1, (7, 7), strides=(1, 1), padding='same', activation='sigmoid')\n","    self.AE = AE()\n","\n","  def call(self, inputs):\n","    #for channel attention    \n","    GAP = GlobalAveragePooling2D()(inputs)    \n","    GMP = GlobalMaxPooling2D()(inputs)    \n","    AE1 = self.AE(GAP)\n","    AE2 = self.AE(GMP)\n","    add = Add()([AE1, AE2])\n","    channel_attention = self.relu(add)\n","    multiply1 = Multiply()([inputs, channel_attention])\n","    #for spatial attention\n","    GAP_f = self.AvgPool(multiply1)\n","    GMP_f = self.MaxPool(multiply1)\n","    concat = concatenate([GAP_f, GMP_f])   \n","    spatial_attention = self.conv(concat)\n","    output = Multiply()([multiply1, spatial_attention])    \n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkNoRoRZkljM"},"source":["class GhostModule(Model):\n","  def __init__(self, out, ratio, dwkernel):\n","    super(GhostModule, self).__init__()\n","    self.ratio = ratio\n","    self.out = out\n","    self.conv_out_channel = ceil(self.out * 1.0 / ratio)    \n","    self.conv = Conv2D(int(self.conv_out_channel), (3, 3),\n","                        strides=(1, 1), padding='same', activation='relu')\n","    self.depthconv = DepthwiseConv2D(dwkernel, 1, padding='same',\n","                        depth_multiplier=ratio-1, activation='relu')\n","    self.BN = BatchNormalization()\n","\n","  def call(self, inputs):\n","    x = self.conv(inputs)\n","    if self.ratio == 1:\n","      return x\n","    dw = self.depthconv(x)\n","    dw = dw[:, :, :, :int(self.out - self.conv_out_channel)]\n","    output = self.BN(concatenate([x, dw]))\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfJ4SzmPLSrn"},"source":["class GhostVGG16(Model):\n","  def __init__(self):\n","    super(GhostVGG16, self).__init__()\n","    self.outs = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]       \n","    self.ratio = [2]*13\n","    self.dwkernek = [3]*13\n","    self.flatten = Flatten()\n","    self.MaxPooling = MaxPooling2D((2,2))\n","    self.dense1 = Dense(4096, activation='relu')\n","    self.dense2 = Dense(4096, activation='relu')\n","    self.dense3 = Dense(10, activation='softmax')    \n","    self.dropout = Dropout(0.5)\n","    for i, args in enumerate(zip(self.outs, self.ratio, self.dwkernek)):\n","      setattr(self, f\"Gmodule{i+1}\", GhostModule(*args)) \n","    for i in range(1):\n","      setattr(self, f\"CBAM{i+1}\", CBAM())\n","    \n","  def call(self, inputs):        \n","    #2 x 64    \n","    #x = self.G_Module0(inputs)\n","    x = getattr(self, f\"Gmodule1\")(inputs) \n","    #x = getattr(self, f\"CBAM1\")(x) \n","    x = getattr(self, f\"Gmodule2\")(x)\n","    x = self.MaxPooling(x)\n","    #2 x 128\n","    x = getattr(self, f\"Gmodule3\")(x) \n","    #x = getattr(self, f\"CBAM2\")(x) \n","    x = getattr(self, f\"Gmodule4\")(x)\n","    x = self.MaxPooling(x)\n","    #3 x 256\n","    x = getattr(self, f\"Gmodule5\")(x) \n","    x = getattr(self, f\"Gmodule6\")(x) \n","    x = getattr(self, f\"CBAM1\")(x)    \n","    x = getattr(self, f\"Gmodule7\")(x) \n","    x = self.MaxPooling(x)\n","    #3 x 512\n","    x = getattr(self, f\"Gmodule8\")(x) \n","    x = getattr(self, f\"Gmodule9\")(x)\n","    x = getattr(self, f\"Gmodule10\")(x)\n","    x = self.MaxPooling(x)\n","    #3 x 512\n","    x = getattr(self, f\"Gmodule11\")(x)  \n","    x = getattr(self, f\"Gmodule12\")(x)\n","    x = getattr(self, f\"Gmodule13\")(x)\n","    x = self.MaxPooling(x)  \n","    #flat  \n","    flat = self.flatten(x)\n","    x = self.dense1(flat)\n","    x = self.dropout(x)\n","    x = self.dense2(x)\n","    x = self.dropout(x)\n","    #dense 10\n","    output = self.dense3(x)\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DBf3x-eMlNuD"},"source":["def scheduler(epoch):\n","  learning_rate = 0.001\n","  if epoch < epoch_num * 0.4:\n","    return learning_rate\n","  if epoch < epoch_num * 0.8:\n","    return learning_rate * 0.1\n","  return learning_rate * 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zeWWKc4biyF4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624170880925,"user_tz":-480,"elapsed":14971,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}},"outputId":"fd1bb783-fee2-4ecb-8e44-505c652460fa"},"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZzgzNTkMjZBm"},"source":["x_train = tf.cast(x_train, tf.float32)\n","x_test = tf.cast(x_test, tf.float32)\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWPdTjRkgEzr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624170884480,"user_tz":-480,"elapsed":8,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}},"outputId":"79e07be8-855e-4824-bf1e-d37ae665a3cc"},"source":["tf.shape(x_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=int32, numpy=array([50000,    32,    32,     3], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"9Ctvp4y_OLHI"},"source":["IMAGE_SIZE = 32\n","batch_size = 64\n","epoch_num = 50\n","AUTO = tf.data.AUTOTUNE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gh7hcBDmFlr0"},"source":["simple_aug = tf.keras.Sequential(\n","    [\n","        layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n","        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","        layers.experimental.preprocessing.RandomRotation(factor=0.02),\n","        layers.experimental.preprocessing.RandomZoom(\n","            height_factor=0.2, width_factor=0.2\n","        ),\n","    ]\n",")\n","\n","# Now, map the augmentation pipeline to our training dataset\n","train_ds_simple = (\n","    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","    .shuffle(64 * 100)\n","    .batch(64)\n","    .map(lambda x, y: (simple_aug(x), y), num_parallel_calls=AUTO)\n","    .prefetch(AUTO)\n",")\n","\n","test_ds_simple = (\n","    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","    .shuffle(64 * 100)\n","    .batch(64)\n","    .map(lambda x, y: (simple_aug(x), y), num_parallel_calls=AUTO)\n","    .prefetch(AUTO)\n",") "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTdgizKqC_TC"},"source":["#change_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","sgd = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.09, nesterov=True)\n","#adam = tf.keras.optimizers.Adam(learning_rate=0.0001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_Oax08AjzRU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624170885191,"user_tz":-480,"elapsed":6,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}},"outputId":"bc63c24c-c122-443c-dad3-f09e38d25d5a"},"source":["model = GhostVGG16()\n","model.build(input_shape = (1, 32, 32, 3))\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"ghost_vg_g16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            multiple                  0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) multiple                  0         \n","_________________________________________________________________\n","dense (Dense)                multiple                  2101248   \n","_________________________________________________________________\n","dense_1 (Dense)              multiple                  16781312  \n","_________________________________________________________________\n","dense_2 (Dense)              multiple                  40970     \n","_________________________________________________________________\n","dropout (Dropout)            multiple                  0         \n","_________________________________________________________________\n","ghost_module (GhostModule)   multiple                  1472      \n","_________________________________________________________________\n","ghost_module_1 (GhostModule) multiple                  19040     \n","_________________________________________________________________\n","ghost_module_2 (GhostModule) multiple                  38080     \n","_________________________________________________________________\n","ghost_module_3 (GhostModule) multiple                  74944     \n","_________________________________________________________________\n","ghost_module_4 (GhostModule) multiple                  149888    \n","_________________________________________________________________\n","ghost_module_5 (GhostModule) multiple                  297344    \n","_________________________________________________________________\n","ghost_module_6 (GhostModule) multiple                  297344    \n","_________________________________________________________________\n","ghost_module_7 (GhostModule) multiple                  594688    \n","_________________________________________________________________\n","ghost_module_8 (GhostModule) multiple                  1184512   \n","_________________________________________________________________\n","ghost_module_9 (GhostModule) multiple                  1184512   \n","_________________________________________________________________\n","ghost_module_10 (GhostModule multiple                  1184512   \n","_________________________________________________________________\n","ghost_module_11 (GhostModule multiple                  1184512   \n","_________________________________________________________________\n","ghost_module_12 (GhostModule multiple                  1184512   \n","_________________________________________________________________\n","cbam (CBAM)                  multiple                  95241     \n","=================================================================\n","Total params: 26,414,131\n","Trainable params: 26,405,683\n","Non-trainable params: 8,448\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fZB2pLOaJLbF"},"source":["!nvidia-smi"]},{"cell_type":"code","metadata":{"id":"dBECrF6SFt2t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624174452700,"user_tz":-480,"elapsed":2113799,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}},"outputId":"3ea6f351-10bf-4909-8f41-c1a3a3846259"},"source":["checkpoint = tf.train.Checkpoint(myModel=model)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","history = model.fit(train_ds_simple,\n","          batch_size=batch_size,\n","          epochs=100,          \n","          validation_data=test_ds_simple)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","782/782 [==============================] - 44s 34ms/step - loss: 2.2205 - accuracy: 0.1829 - val_loss: 1.9547 - val_accuracy: 0.2640\n","Epoch 2/100\n","782/782 [==============================] - 27s 34ms/step - loss: 1.8849 - accuracy: 0.2834 - val_loss: 1.7289 - val_accuracy: 0.3565\n","Epoch 3/100\n","782/782 [==============================] - 26s 34ms/step - loss: 1.7172 - accuracy: 0.3547 - val_loss: 1.5796 - val_accuracy: 0.4166\n","Epoch 4/100\n","782/782 [==============================] - 27s 34ms/step - loss: 1.5927 - accuracy: 0.4110 - val_loss: 1.6378 - val_accuracy: 0.4103\n","Epoch 5/100\n","782/782 [==============================] - 27s 34ms/step - loss: 1.4846 - accuracy: 0.4561 - val_loss: 1.3967 - val_accuracy: 0.4911\n","Epoch 6/100\n","782/782 [==============================] - 26s 34ms/step - loss: 1.3966 - accuracy: 0.4916 - val_loss: 1.4842 - val_accuracy: 0.4699\n","Epoch 7/100\n","782/782 [==============================] - 27s 34ms/step - loss: 1.3228 - accuracy: 0.5236 - val_loss: 1.2996 - val_accuracy: 0.5369\n","Epoch 8/100\n","782/782 [==============================] - 27s 35ms/step - loss: 1.2610 - accuracy: 0.5472 - val_loss: 1.2841 - val_accuracy: 0.5456\n","Epoch 9/100\n","782/782 [==============================] - 27s 34ms/step - loss: 1.2119 - accuracy: 0.5655 - val_loss: 1.1674 - val_accuracy: 0.5885\n","Epoch 10/100\n","782/782 [==============================] - 27s 35ms/step - loss: 1.1680 - accuracy: 0.5848 - val_loss: 1.1632 - val_accuracy: 0.5886\n","Epoch 11/100\n","782/782 [==============================] - 27s 35ms/step - loss: 1.1284 - accuracy: 0.5959 - val_loss: 1.1381 - val_accuracy: 0.6000\n","Epoch 12/100\n","782/782 [==============================] - 27s 35ms/step - loss: 1.0865 - accuracy: 0.6134 - val_loss: 1.0995 - val_accuracy: 0.6077\n","Epoch 13/100\n","782/782 [==============================] - 27s 35ms/step - loss: 1.0549 - accuracy: 0.6263 - val_loss: 1.0372 - val_accuracy: 0.6330\n","Epoch 14/100\n","782/782 [==============================] - 27s 35ms/step - loss: 1.0222 - accuracy: 0.6368 - val_loss: 1.0569 - val_accuracy: 0.6280\n","Epoch 15/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.9845 - accuracy: 0.6512 - val_loss: 0.9949 - val_accuracy: 0.6455\n","Epoch 16/100\n","782/782 [==============================] - 27s 34ms/step - loss: 0.9590 - accuracy: 0.6636 - val_loss: 0.9891 - val_accuracy: 0.6541\n","Epoch 17/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.9301 - accuracy: 0.6727 - val_loss: 0.9615 - val_accuracy: 0.6597\n","Epoch 18/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.8991 - accuracy: 0.6837 - val_loss: 0.9527 - val_accuracy: 0.6632\n","Epoch 19/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.8763 - accuracy: 0.6928 - val_loss: 0.9365 - val_accuracy: 0.6748\n","Epoch 20/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.8534 - accuracy: 0.7033 - val_loss: 0.9145 - val_accuracy: 0.6816\n","Epoch 21/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.8279 - accuracy: 0.7102 - val_loss: 0.8742 - val_accuracy: 0.6942\n","Epoch 22/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.8083 - accuracy: 0.7171 - val_loss: 0.9004 - val_accuracy: 0.6890\n","Epoch 23/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.7824 - accuracy: 0.7252 - val_loss: 0.8483 - val_accuracy: 0.7020\n","Epoch 24/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.7669 - accuracy: 0.7317 - val_loss: 0.8220 - val_accuracy: 0.7137\n","Epoch 25/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.7494 - accuracy: 0.7389 - val_loss: 0.8636 - val_accuracy: 0.7049\n","Epoch 26/100\n","782/782 [==============================] - 26s 34ms/step - loss: 0.7292 - accuracy: 0.7446 - val_loss: 0.8027 - val_accuracy: 0.7228\n","Epoch 27/100\n","782/782 [==============================] - 26s 34ms/step - loss: 0.7161 - accuracy: 0.7522 - val_loss: 0.7971 - val_accuracy: 0.7249\n","Epoch 28/100\n","782/782 [==============================] - 27s 34ms/step - loss: 0.6984 - accuracy: 0.7580 - val_loss: 0.7811 - val_accuracy: 0.7283\n","Epoch 29/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.6849 - accuracy: 0.7605 - val_loss: 0.7871 - val_accuracy: 0.7303\n","Epoch 30/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.6672 - accuracy: 0.7692 - val_loss: 0.7842 - val_accuracy: 0.7323\n","Epoch 31/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.6519 - accuracy: 0.7743 - val_loss: 0.7550 - val_accuracy: 0.7434\n","Epoch 32/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.6391 - accuracy: 0.7791 - val_loss: 0.7685 - val_accuracy: 0.7359\n","Epoch 33/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.6244 - accuracy: 0.7826 - val_loss: 0.7763 - val_accuracy: 0.7361\n","Epoch 34/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.6184 - accuracy: 0.7839 - val_loss: 0.7529 - val_accuracy: 0.7425\n","Epoch 35/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.6045 - accuracy: 0.7881 - val_loss: 0.7649 - val_accuracy: 0.7426\n","Epoch 36/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.5946 - accuracy: 0.7936 - val_loss: 0.7403 - val_accuracy: 0.7471\n","Epoch 37/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.5756 - accuracy: 0.8005 - val_loss: 0.7242 - val_accuracy: 0.7550\n","Epoch 38/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.5653 - accuracy: 0.8039 - val_loss: 0.7301 - val_accuracy: 0.7478\n","Epoch 39/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.5522 - accuracy: 0.8093 - val_loss: 0.7334 - val_accuracy: 0.7587\n","Epoch 40/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.5472 - accuracy: 0.8096 - val_loss: 0.7802 - val_accuracy: 0.7370\n","Epoch 41/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.5333 - accuracy: 0.8150 - val_loss: 0.7655 - val_accuracy: 0.7456\n","Epoch 42/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.5259 - accuracy: 0.8169 - val_loss: 0.7237 - val_accuracy: 0.7589\n","Epoch 43/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.5163 - accuracy: 0.8209 - val_loss: 0.7377 - val_accuracy: 0.7525\n","Epoch 44/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.5040 - accuracy: 0.8247 - val_loss: 0.7334 - val_accuracy: 0.7605\n","Epoch 45/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.4933 - accuracy: 0.8303 - val_loss: 0.7171 - val_accuracy: 0.7591\n","Epoch 46/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.4805 - accuracy: 0.8339 - val_loss: 0.7624 - val_accuracy: 0.7560\n","Epoch 47/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.4758 - accuracy: 0.8324 - val_loss: 0.7399 - val_accuracy: 0.7583\n","Epoch 48/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.4636 - accuracy: 0.8383 - val_loss: 0.7099 - val_accuracy: 0.7606\n","Epoch 49/100\n","782/782 [==============================] - 27s 35ms/step - loss: 0.4552 - accuracy: 0.8419 - val_loss: 0.7314 - val_accuracy: 0.7624\n","Epoch 50/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.4480 - accuracy: 0.8440 - val_loss: 0.7065 - val_accuracy: 0.7736\n","Epoch 51/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.4365 - accuracy: 0.8510 - val_loss: 0.7157 - val_accuracy: 0.7682\n","Epoch 52/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.4243 - accuracy: 0.8518 - val_loss: 0.7361 - val_accuracy: 0.7684\n","Epoch 53/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.4203 - accuracy: 0.8547 - val_loss: 0.7829 - val_accuracy: 0.7526\n","Epoch 54/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.4154 - accuracy: 0.8543 - val_loss: 0.7577 - val_accuracy: 0.7591\n","Epoch 55/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.4020 - accuracy: 0.8603 - val_loss: 0.7733 - val_accuracy: 0.7568\n","Epoch 56/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.3940 - accuracy: 0.8617 - val_loss: 0.7388 - val_accuracy: 0.7654\n","Epoch 57/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.3896 - accuracy: 0.8656 - val_loss: 0.7648 - val_accuracy: 0.7627\n","Epoch 58/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.3825 - accuracy: 0.8667 - val_loss: 0.7768 - val_accuracy: 0.7639\n","Epoch 59/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.3691 - accuracy: 0.8706 - val_loss: 0.7740 - val_accuracy: 0.7602\n","Epoch 60/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.3639 - accuracy: 0.8746 - val_loss: 0.7466 - val_accuracy: 0.7699\n","Epoch 61/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.3582 - accuracy: 0.8750 - val_loss: 0.8047 - val_accuracy: 0.7533\n","Epoch 62/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.3487 - accuracy: 0.8792 - val_loss: 0.7603 - val_accuracy: 0.7711\n","Epoch 63/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.3432 - accuracy: 0.8796 - val_loss: 0.7616 - val_accuracy: 0.7714\n","Epoch 64/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.3356 - accuracy: 0.8833 - val_loss: 0.7487 - val_accuracy: 0.7725\n","Epoch 65/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.3277 - accuracy: 0.8848 - val_loss: 0.7376 - val_accuracy: 0.7729\n","Epoch 66/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.3207 - accuracy: 0.8891 - val_loss: 0.7328 - val_accuracy: 0.7763\n","Epoch 67/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.3165 - accuracy: 0.8899 - val_loss: 0.7928 - val_accuracy: 0.7663\n","Epoch 68/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.3105 - accuracy: 0.8904 - val_loss: 0.7670 - val_accuracy: 0.7706\n","Epoch 69/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.3063 - accuracy: 0.8948 - val_loss: 0.7536 - val_accuracy: 0.7745\n","Epoch 70/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2940 - accuracy: 0.8987 - val_loss: 0.8399 - val_accuracy: 0.7566\n","Epoch 71/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2986 - accuracy: 0.8954 - val_loss: 0.7976 - val_accuracy: 0.7678\n","Epoch 72/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2909 - accuracy: 0.9001 - val_loss: 0.7653 - val_accuracy: 0.7772\n","Epoch 73/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2821 - accuracy: 0.9022 - val_loss: 0.7898 - val_accuracy: 0.7709\n","Epoch 74/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2642 - accuracy: 0.9084 - val_loss: 0.7763 - val_accuracy: 0.7756\n","Epoch 75/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2618 - accuracy: 0.9089 - val_loss: 0.7770 - val_accuracy: 0.7809\n","Epoch 76/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.2593 - accuracy: 0.9095 - val_loss: 0.8097 - val_accuracy: 0.7711\n","Epoch 77/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.2560 - accuracy: 0.9100 - val_loss: 0.8007 - val_accuracy: 0.7767\n","Epoch 78/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2479 - accuracy: 0.9130 - val_loss: 0.8356 - val_accuracy: 0.7703\n","Epoch 79/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2482 - accuracy: 0.9143 - val_loss: 0.7977 - val_accuracy: 0.7765\n","Epoch 80/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2445 - accuracy: 0.9147 - val_loss: 0.7750 - val_accuracy: 0.7821\n","Epoch 81/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2399 - accuracy: 0.9161 - val_loss: 0.8218 - val_accuracy: 0.7756\n","Epoch 82/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.2312 - accuracy: 0.9194 - val_loss: 0.7967 - val_accuracy: 0.7809\n","Epoch 83/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.2260 - accuracy: 0.9203 - val_loss: 0.8287 - val_accuracy: 0.7756\n","Epoch 84/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.2218 - accuracy: 0.9243 - val_loss: 0.8925 - val_accuracy: 0.7551\n","Epoch 85/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2137 - accuracy: 0.9249 - val_loss: 0.8252 - val_accuracy: 0.7772\n","Epoch 86/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2091 - accuracy: 0.9285 - val_loss: 0.8336 - val_accuracy: 0.7764\n","Epoch 87/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2043 - accuracy: 0.9279 - val_loss: 0.8570 - val_accuracy: 0.7719\n","Epoch 88/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.2079 - accuracy: 0.9275 - val_loss: 0.8289 - val_accuracy: 0.7763\n","Epoch 89/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.2043 - accuracy: 0.9285 - val_loss: 0.8905 - val_accuracy: 0.7706\n","Epoch 90/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1924 - accuracy: 0.9329 - val_loss: 0.8367 - val_accuracy: 0.7820\n","Epoch 91/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1972 - accuracy: 0.9316 - val_loss: 0.8850 - val_accuracy: 0.7722\n","Epoch 92/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1835 - accuracy: 0.9366 - val_loss: 0.8763 - val_accuracy: 0.7709\n","Epoch 93/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1824 - accuracy: 0.9373 - val_loss: 0.9255 - val_accuracy: 0.7613\n","Epoch 94/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1800 - accuracy: 0.9364 - val_loss: 0.8781 - val_accuracy: 0.7809\n","Epoch 95/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1758 - accuracy: 0.9390 - val_loss: 0.8400 - val_accuracy: 0.7838\n","Epoch 96/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1768 - accuracy: 0.9379 - val_loss: 0.8532 - val_accuracy: 0.7781\n","Epoch 97/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1710 - accuracy: 0.9412 - val_loss: 0.8808 - val_accuracy: 0.7756\n","Epoch 98/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1667 - accuracy: 0.9419 - val_loss: 0.8865 - val_accuracy: 0.7773\n","Epoch 99/100\n","782/782 [==============================] - 28s 36ms/step - loss: 0.1632 - accuracy: 0.9427 - val_loss: 0.8595 - val_accuracy: 0.7794\n","Epoch 100/100\n","782/782 [==============================] - 28s 35ms/step - loss: 0.1619 - accuracy: 0.9448 - val_loss: 0.8985 - val_accuracy: 0.7781\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mh_E4wYagihs","colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"error","timestamp":1624163966473,"user_tz":-480,"elapsed":10,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}},"outputId":"9d081a3a-364b-4459-f8e4-1af7f1e5dbed"},"source":["model.metrics_names"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-50796fac6b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"DS5QykzdX_yc","executionInfo":{"status":"aborted","timestamp":1624163966472,"user_tz":-480,"elapsed":5,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}}},"source":["# summarize history for accuracy\n","from matplotlib import pyplot as plt\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xbY7NhvGVGaM"},"source":["checkpoint.save('/content/drive/MyDrive/Colab Notebooks/2021/paper/CBAM_GhostNet/weightmodel.ckpt')"],"execution_count":null,"outputs":[]}]}