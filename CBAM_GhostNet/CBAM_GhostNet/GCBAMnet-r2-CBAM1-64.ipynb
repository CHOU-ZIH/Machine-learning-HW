{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GCBAMnet-r2-CBAM1-64.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1MjFDoENvVZnpOSaYgF0jxAm3-RfolEcn","authorship_tag":"ABX9TyMjWD8D8tHOE3n4JLy3C+nl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nktdswoSjaAz"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.layers import Conv2D, concatenate, BatchNormalization, DepthwiseConv2D\n","from tensorflow.keras.layers import Lambda, Reshape, Layer, Activation, Add, Multiply\n","from tensorflow.keras import layers\n","from math import ceil\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDukHV149z9r"},"source":["class AE(Model):\n","  def __init__(self):\n","    super(AE, self).__init__()\n","    self.code = Dense(8,activation = 'relu')\n","  def build(self, input_shape):\n","    self.dense1 = Dense(input_shape[-1], activation = 'relu')\n","    self.dense2 = Dense(input_shape[-1], activation = 'relu')\n","  def call(self, inputs):    \n","    d1 = self.dense1(inputs)\n","    code = self.code(d1)\n","    d2 = self.dense2(code)    \n","    return d2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEIzitAPzu5S"},"source":["class CBAM(Model):\n","  def __init__(self):\n","    super(CBAM, self).__init__()          \n","    self.relu = Activation('relu') \n","    self.AvgPool = AveragePooling2D(pool_size=(2, 2),strides=(1, 1), padding='same')\n","    self.MaxPool = MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='same')    \n","    self.conv = Conv2D(1, (7, 7), strides=(1, 1), padding='same', activation='sigmoid')\n","    self.AE = AE()\n","\n","  def call(self, inputs):\n","    #for channel attention    \n","    GAP = GlobalAveragePooling2D()(inputs)    \n","    GMP = GlobalMaxPooling2D()(inputs)    \n","    AE1 = self.AE(GAP)\n","    AE2 = self.AE(GMP)\n","    add = Add()([AE1, AE2])\n","    channel_attention = self.relu(add)\n","    multiply1 = Multiply()([inputs, channel_attention])\n","    #for spatial attention\n","    GAP_f = self.AvgPool(multiply1)\n","    GMP_f = self.MaxPool(multiply1)\n","    concat = concatenate([GAP_f, GMP_f])   \n","    spatial_attention = self.conv(concat)\n","    output = Multiply()([multiply1, spatial_attention])    \n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkNoRoRZkljM"},"source":["class GhostModule(Model):\n","  def __init__(self, out, ratio, dwkernel):\n","    super(GhostModule, self).__init__()\n","    self.ratio = ratio\n","    self.out = out\n","    self.conv_out_channel = ceil(self.out * 1.0 / ratio)    \n","    self.conv = Conv2D(int(self.conv_out_channel), (3, 3),\n","                        strides=(1, 1), padding='same', activation='relu')\n","    self.depthconv = DepthwiseConv2D(dwkernel, 1, padding='same',\n","                        depth_multiplier=ratio-1, activation='relu')\n","    self.BN = BatchNormalization()\n","\n","  def call(self, inputs):\n","    x = self.conv(inputs)\n","    if self.ratio == 1:\n","      return x\n","    dw = self.depthconv(x)\n","    dw = dw[:, :, :, :int(self.out - self.conv_out_channel)]\n","    output = self.BN(concatenate([x, dw]))\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfJ4SzmPLSrn"},"source":["class GhostVGG16(Model):\n","  def __init__(self):\n","    super(GhostVGG16, self).__init__()\n","    self.outs = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]       \n","    self.ratio = [2]*13\n","    self.dwkernek = [3]*13\n","    self.flatten = Flatten()\n","    self.MaxPooling = MaxPooling2D((2,2))\n","    self.dense1 = Dense(4096, activation='relu')\n","    self.dense2 = Dense(4096, activation='relu')\n","    self.dense3 = Dense(10, activation='softmax')    \n","    self.dropout = Dropout(0.5)\n","    for i, args in enumerate(zip(self.outs, self.ratio, self.dwkernek)):\n","      setattr(self, f\"Gmodule{i+1}\", GhostModule(*args)) \n","    for i in range(1):\n","      setattr(self, f\"CBAM{i+1}\", CBAM())\n","    \n","  def call(self, inputs):        \n","    #2 x 64    \n","    #x = self.G_Module0(inputs)\n","    x = getattr(self, f\"Gmodule1\")(inputs) \n","    #x = getattr(self, f\"CBAM1\")(x) \n","    x = getattr(self, f\"CBAM1\")(x) \n","    x = getattr(self, f\"Gmodule2\")(x)\n","    x = self.MaxPooling(x)\n","    #2 x 128\n","    x = getattr(self, f\"Gmodule3\")(x) \n","    #x = getattr(self, f\"CBAM2\")(x) \n","    x = getattr(self, f\"Gmodule4\")(x)\n","    x = self.MaxPooling(x)\n","    #3 x 256\n","    x = getattr(self, f\"Gmodule5\")(x) \n","    x = getattr(self, f\"Gmodule6\")(x)        \n","    x = getattr(self, f\"Gmodule7\")(x) \n","    x = self.MaxPooling(x)\n","    #3 x 512\n","    x = getattr(self, f\"Gmodule8\")(x) \n","    x = getattr(self, f\"Gmodule9\")(x)\n","    x = getattr(self, f\"Gmodule10\")(x)\n","    x = self.MaxPooling(x)\n","    #3 x 512\n","    x = getattr(self, f\"Gmodule11\")(x)  \n","    x = getattr(self, f\"Gmodule12\")(x)\n","    x = getattr(self, f\"Gmodule13\")(x)\n","    x = self.MaxPooling(x)  \n","    #flat  \n","    flat = self.flatten(x)\n","    x = self.dense1(flat)\n","    x = self.dropout(x)\n","    x = self.dense2(x)\n","    x = self.dropout(x)\n","    #dense 10\n","    output = self.dense3(x)\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DBf3x-eMlNuD"},"source":["def scheduler(epoch):\n","  learning_rate = 0.001\n","  if epoch < epoch_num * 0.4:\n","    return learning_rate\n","  if epoch < epoch_num * 0.8:\n","    return learning_rate * 0.1\n","  return learning_rate * 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zeWWKc4biyF4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624172570345,"user_tz":-480,"elapsed":6016,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}},"outputId":"019fca75-ad41-4e3e-d5b7-b75623da69f2"},"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZzgzNTkMjZBm"},"source":["x_train = tf.cast(x_train, tf.float32)\n","x_test = tf.cast(x_test, tf.float32)\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWPdTjRkgEzr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624172573933,"user_tz":-480,"elapsed":11,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}},"outputId":"b27f998c-ce59-4379-85a0-ac75d9a24df0"},"source":["tf.shape(x_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=int32, numpy=array([50000,    32,    32,     3], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"9Ctvp4y_OLHI"},"source":["IMAGE_SIZE = 32\n","batch_size = 64\n","epoch_num = 50\n","AUTO = tf.data.AUTOTUNE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gh7hcBDmFlr0"},"source":["simple_aug = tf.keras.Sequential(\n","    [\n","        layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n","        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","        layers.experimental.preprocessing.RandomRotation(factor=0.02),\n","        layers.experimental.preprocessing.RandomZoom(\n","            height_factor=0.2, width_factor=0.2\n","        ),\n","    ]\n",")\n","\n","# Now, map the augmentation pipeline to our training dataset\n","train_ds_simple = (\n","    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","    .shuffle(64 * 100)\n","    .batch(64)\n","    .map(lambda x, y: (simple_aug(x), y), num_parallel_calls=AUTO)\n","    .prefetch(AUTO)\n",")\n","\n","test_ds_simple = (\n","    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","    .shuffle(64 * 100)\n","    .batch(64)\n","    .map(lambda x, y: (simple_aug(x), y), num_parallel_calls=AUTO)\n","    .prefetch(AUTO)\n",") "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTdgizKqC_TC"},"source":["#change_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","sgd = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.09, nesterov=True)\n","#adam = tf.keras.optimizers.Adam(learning_rate=0.0001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_Oax08AjzRU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624172575311,"user_tz":-480,"elapsed":452,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}},"outputId":"e29ce20f-a7a2-462a-b4e8-37ba23b5d9a9"},"source":["model = GhostVGG16()\n","model.build(input_shape = (1, 32, 32, 3))\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"ghost_vg_g16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            multiple                  0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) multiple                  0         \n","_________________________________________________________________\n","dense (Dense)                multiple                  2101248   \n","_________________________________________________________________\n","dense_1 (Dense)              multiple                  16781312  \n","_________________________________________________________________\n","dense_2 (Dense)              multiple                  40970     \n","_________________________________________________________________\n","dropout (Dropout)            multiple                  0         \n","_________________________________________________________________\n","ghost_module (GhostModule)   multiple                  1472      \n","_________________________________________________________________\n","ghost_module_1 (GhostModule) multiple                  19040     \n","_________________________________________________________________\n","ghost_module_2 (GhostModule) multiple                  38080     \n","_________________________________________________________________\n","ghost_module_3 (GhostModule) multiple                  74944     \n","_________________________________________________________________\n","ghost_module_4 (GhostModule) multiple                  149888    \n","_________________________________________________________________\n","ghost_module_5 (GhostModule) multiple                  297344    \n","_________________________________________________________________\n","ghost_module_6 (GhostModule) multiple                  297344    \n","_________________________________________________________________\n","ghost_module_7 (GhostModule) multiple                  594688    \n","_________________________________________________________________\n","ghost_module_8 (GhostModule) multiple                  1184512   \n","_________________________________________________________________\n","ghost_module_9 (GhostModule) multiple                  1184512   \n","_________________________________________________________________\n","ghost_module_10 (GhostModule multiple                  1184512   \n","_________________________________________________________________\n","ghost_module_11 (GhostModule multiple                  1184512   \n","_________________________________________________________________\n","ghost_module_12 (GhostModule multiple                  1184512   \n","_________________________________________________________________\n","cbam (CBAM)                  multiple                  11529     \n","=================================================================\n","Total params: 26,330,419\n","Trainable params: 26,321,971\n","Non-trainable params: 8,448\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fZB2pLOaJLbF"},"source":["!nvidia-smi"]},{"cell_type":"code","metadata":{"id":"dBECrF6SFt2t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624176102457,"user_tz":-480,"elapsed":3527150,"user":{"displayName":"周子玄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixTgIB08GMjp9BHKozu0VfHBF0MfWJhYYCiR1i=s64","userId":"06482969277874528579"}},"outputId":"816fb113-6824-44f4-8b44-be0857215b81"},"source":["checkpoint = tf.train.Checkpoint(myModel=model)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","history = model.fit(train_ds_simple,\n","          batch_size=batch_size,\n","          epochs=100,          \n","          validation_data=test_ds_simple)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","782/782 [==============================] - 48s 38ms/step - loss: 2.3610 - accuracy: 0.1437 - val_loss: 2.4550 - val_accuracy: 0.1140\n","Epoch 2/100\n","782/782 [==============================] - 29s 37ms/step - loss: 2.0099 - accuracy: 0.2465 - val_loss: 1.8425 - val_accuracy: 0.3215\n","Epoch 3/100\n","782/782 [==============================] - 30s 38ms/step - loss: 1.7705 - accuracy: 0.3345 - val_loss: 1.8666 - val_accuracy: 0.3425\n","Epoch 4/100\n","782/782 [==============================] - 30s 38ms/step - loss: 1.6268 - accuracy: 0.3986 - val_loss: 1.9431 - val_accuracy: 0.3363\n","Epoch 5/100\n","782/782 [==============================] - 29s 37ms/step - loss: 1.5430 - accuracy: 0.4357 - val_loss: 1.4256 - val_accuracy: 0.4760\n","Epoch 6/100\n","782/782 [==============================] - 29s 38ms/step - loss: 1.4503 - accuracy: 0.4740 - val_loss: 1.3621 - val_accuracy: 0.5093\n","Epoch 7/100\n","782/782 [==============================] - 29s 37ms/step - loss: 1.3901 - accuracy: 0.4970 - val_loss: 1.3272 - val_accuracy: 0.5176\n","Epoch 8/100\n","782/782 [==============================] - 29s 37ms/step - loss: 1.3271 - accuracy: 0.5209 - val_loss: 1.3829 - val_accuracy: 0.5162\n","Epoch 9/100\n","782/782 [==============================] - 29s 38ms/step - loss: 1.2681 - accuracy: 0.5428 - val_loss: 1.2388 - val_accuracy: 0.5510\n","Epoch 10/100\n","782/782 [==============================] - 29s 37ms/step - loss: 1.2048 - accuracy: 0.5666 - val_loss: 1.1351 - val_accuracy: 0.5971\n","Epoch 11/100\n","782/782 [==============================] - 29s 37ms/step - loss: 1.1626 - accuracy: 0.5861 - val_loss: 1.1937 - val_accuracy: 0.5812\n","Epoch 12/100\n","782/782 [==============================] - 30s 38ms/step - loss: 1.1167 - accuracy: 0.6029 - val_loss: 1.1071 - val_accuracy: 0.6103\n","Epoch 13/100\n","782/782 [==============================] - 29s 37ms/step - loss: 1.0761 - accuracy: 0.6213 - val_loss: 1.0897 - val_accuracy: 0.6137\n","Epoch 14/100\n","782/782 [==============================] - 29s 38ms/step - loss: 1.0348 - accuracy: 0.6326 - val_loss: 1.0979 - val_accuracy: 0.6138\n","Epoch 15/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.9970 - accuracy: 0.6500 - val_loss: 1.0567 - val_accuracy: 0.6306\n","Epoch 16/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.9654 - accuracy: 0.6584 - val_loss: 1.0831 - val_accuracy: 0.6190\n","Epoch 17/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.9403 - accuracy: 0.6686 - val_loss: 0.9602 - val_accuracy: 0.6617\n","Epoch 18/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.9116 - accuracy: 0.6798 - val_loss: 0.9769 - val_accuracy: 0.6598\n","Epoch 19/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.8877 - accuracy: 0.6901 - val_loss: 0.8929 - val_accuracy: 0.6904\n","Epoch 20/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.8615 - accuracy: 0.6991 - val_loss: 0.8827 - val_accuracy: 0.6906\n","Epoch 21/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.8339 - accuracy: 0.7073 - val_loss: 0.8941 - val_accuracy: 0.6850\n","Epoch 22/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.8164 - accuracy: 0.7144 - val_loss: 0.8698 - val_accuracy: 0.6972\n","Epoch 23/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.7919 - accuracy: 0.7236 - val_loss: 0.9457 - val_accuracy: 0.6794\n","Epoch 24/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.7820 - accuracy: 0.7281 - val_loss: 0.8346 - val_accuracy: 0.7105\n","Epoch 25/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.7529 - accuracy: 0.7382 - val_loss: 0.8360 - val_accuracy: 0.7110\n","Epoch 26/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.7340 - accuracy: 0.7416 - val_loss: 0.8105 - val_accuracy: 0.7231\n","Epoch 27/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.7179 - accuracy: 0.7494 - val_loss: 0.8225 - val_accuracy: 0.7209\n","Epoch 28/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.7027 - accuracy: 0.7564 - val_loss: 0.9072 - val_accuracy: 0.6907\n","Epoch 29/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.6870 - accuracy: 0.7620 - val_loss: 0.7679 - val_accuracy: 0.7378\n","Epoch 30/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.6699 - accuracy: 0.7664 - val_loss: 0.8462 - val_accuracy: 0.7096\n","Epoch 31/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.6596 - accuracy: 0.7710 - val_loss: 0.7552 - val_accuracy: 0.7394\n","Epoch 32/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.6419 - accuracy: 0.7778 - val_loss: 0.7646 - val_accuracy: 0.7367\n","Epoch 33/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.6352 - accuracy: 0.7801 - val_loss: 0.7638 - val_accuracy: 0.7422\n","Epoch 34/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.6164 - accuracy: 0.7850 - val_loss: 0.7544 - val_accuracy: 0.7394\n","Epoch 35/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.6031 - accuracy: 0.7897 - val_loss: 0.7603 - val_accuracy: 0.7409\n","Epoch 36/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.5911 - accuracy: 0.7970 - val_loss: 0.7276 - val_accuracy: 0.7552\n","Epoch 37/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.5787 - accuracy: 0.7971 - val_loss: 0.7357 - val_accuracy: 0.7532\n","Epoch 38/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.5660 - accuracy: 0.8048 - val_loss: 0.7522 - val_accuracy: 0.7528\n","Epoch 39/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.5538 - accuracy: 0.8086 - val_loss: 0.7432 - val_accuracy: 0.7436\n","Epoch 40/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.5408 - accuracy: 0.8129 - val_loss: 0.8186 - val_accuracy: 0.7280\n","Epoch 41/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.5295 - accuracy: 0.8169 - val_loss: 0.7456 - val_accuracy: 0.7538\n","Epoch 42/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.5235 - accuracy: 0.8187 - val_loss: 0.7383 - val_accuracy: 0.7561\n","Epoch 43/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.5101 - accuracy: 0.8218 - val_loss: 0.7299 - val_accuracy: 0.7592\n","Epoch 44/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4984 - accuracy: 0.8261 - val_loss: 0.7419 - val_accuracy: 0.7528\n","Epoch 45/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4915 - accuracy: 0.8294 - val_loss: 0.7706 - val_accuracy: 0.7485\n","Epoch 46/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4809 - accuracy: 0.8333 - val_loss: 0.9784 - val_accuracy: 0.6939\n","Epoch 47/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4625 - accuracy: 0.8390 - val_loss: 0.7080 - val_accuracy: 0.7656\n","Epoch 48/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4586 - accuracy: 0.8404 - val_loss: 0.7281 - val_accuracy: 0.7618\n","Epoch 49/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4546 - accuracy: 0.8434 - val_loss: 0.7554 - val_accuracy: 0.7562\n","Epoch 50/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4404 - accuracy: 0.8482 - val_loss: 0.7258 - val_accuracy: 0.7662\n","Epoch 51/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4301 - accuracy: 0.8498 - val_loss: 0.7127 - val_accuracy: 0.7685\n","Epoch 52/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4254 - accuracy: 0.8513 - val_loss: 0.7782 - val_accuracy: 0.7548\n","Epoch 53/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.7569 - val_accuracy: 0.7568\n","Epoch 54/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.4028 - accuracy: 0.8606 - val_loss: 0.7386 - val_accuracy: 0.7636\n","Epoch 55/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.3956 - accuracy: 0.8646 - val_loss: 0.7209 - val_accuracy: 0.7701\n","Epoch 56/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.3889 - accuracy: 0.8655 - val_loss: 0.7250 - val_accuracy: 0.7669\n","Epoch 57/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.3824 - accuracy: 0.8681 - val_loss: 0.7690 - val_accuracy: 0.7598\n","Epoch 58/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.3716 - accuracy: 0.8706 - val_loss: 0.7162 - val_accuracy: 0.7759\n","Epoch 59/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.3610 - accuracy: 0.8759 - val_loss: 0.7839 - val_accuracy: 0.7598\n","Epoch 60/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.3518 - accuracy: 0.8773 - val_loss: 0.7454 - val_accuracy: 0.7687\n","Epoch 61/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.3533 - accuracy: 0.8778 - val_loss: 0.7754 - val_accuracy: 0.7661\n","Epoch 62/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.3382 - accuracy: 0.8828 - val_loss: 0.7728 - val_accuracy: 0.7662\n","Epoch 63/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.3342 - accuracy: 0.8843 - val_loss: 0.7545 - val_accuracy: 0.7788\n","Epoch 64/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.3258 - accuracy: 0.8864 - val_loss: 0.7584 - val_accuracy: 0.7698\n","Epoch 65/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.3170 - accuracy: 0.8893 - val_loss: 0.7442 - val_accuracy: 0.7738\n","Epoch 66/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.3116 - accuracy: 0.8913 - val_loss: 0.7873 - val_accuracy: 0.7661\n","Epoch 67/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.3049 - accuracy: 0.8942 - val_loss: 0.7374 - val_accuracy: 0.7746\n","Epoch 68/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.3004 - accuracy: 0.8964 - val_loss: 0.7569 - val_accuracy: 0.7751\n","Epoch 69/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.2923 - accuracy: 0.8978 - val_loss: 0.8299 - val_accuracy: 0.7607\n","Epoch 70/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.2849 - accuracy: 0.9017 - val_loss: 0.7585 - val_accuracy: 0.7755\n","Epoch 71/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.2777 - accuracy: 0.9033 - val_loss: 0.7961 - val_accuracy: 0.7678\n","Epoch 72/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.2760 - accuracy: 0.9044 - val_loss: 0.7654 - val_accuracy: 0.7787\n","Epoch 73/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.2706 - accuracy: 0.9061 - val_loss: 0.7769 - val_accuracy: 0.7772\n","Epoch 74/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2605 - accuracy: 0.9089 - val_loss: 0.7992 - val_accuracy: 0.7734\n","Epoch 75/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.2525 - accuracy: 0.9125 - val_loss: 0.8169 - val_accuracy: 0.7696\n","Epoch 76/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.2538 - accuracy: 0.9119 - val_loss: 0.8289 - val_accuracy: 0.7633\n","Epoch 77/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2497 - accuracy: 0.9133 - val_loss: 0.8507 - val_accuracy: 0.7605\n","Epoch 78/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.2429 - accuracy: 0.9150 - val_loss: 0.8120 - val_accuracy: 0.7758\n","Epoch 79/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2352 - accuracy: 0.9192 - val_loss: 0.8102 - val_accuracy: 0.7730\n","Epoch 80/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2271 - accuracy: 0.9213 - val_loss: 0.8252 - val_accuracy: 0.7740\n","Epoch 81/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2243 - accuracy: 0.9214 - val_loss: 0.8285 - val_accuracy: 0.7676\n","Epoch 82/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2225 - accuracy: 0.9222 - val_loss: 0.8131 - val_accuracy: 0.7753\n","Epoch 83/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2177 - accuracy: 0.9238 - val_loss: 0.8586 - val_accuracy: 0.7683\n","Epoch 84/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2115 - accuracy: 0.9275 - val_loss: 0.8422 - val_accuracy: 0.7714\n","Epoch 85/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2073 - accuracy: 0.9288 - val_loss: 0.8671 - val_accuracy: 0.7715\n","Epoch 86/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.2053 - accuracy: 0.9281 - val_loss: 0.8069 - val_accuracy: 0.7805\n","Epoch 87/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.1979 - accuracy: 0.9312 - val_loss: 0.8327 - val_accuracy: 0.7770\n","Epoch 88/100\n","782/782 [==============================] - 30s 38ms/step - loss: 0.1935 - accuracy: 0.9331 - val_loss: 0.8607 - val_accuracy: 0.7759\n","Epoch 89/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1928 - accuracy: 0.9331 - val_loss: 0.9273 - val_accuracy: 0.7667\n","Epoch 90/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1900 - accuracy: 0.9334 - val_loss: 0.8648 - val_accuracy: 0.7701\n","Epoch 91/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1842 - accuracy: 0.9364 - val_loss: 0.8423 - val_accuracy: 0.7782\n","Epoch 92/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1802 - accuracy: 0.9379 - val_loss: 0.8751 - val_accuracy: 0.7797\n","Epoch 93/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1769 - accuracy: 0.9393 - val_loss: 0.9424 - val_accuracy: 0.7687\n","Epoch 94/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1767 - accuracy: 0.9388 - val_loss: 0.8772 - val_accuracy: 0.7742\n","Epoch 95/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1673 - accuracy: 0.9429 - val_loss: 0.8656 - val_accuracy: 0.7759\n","Epoch 96/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1632 - accuracy: 0.9443 - val_loss: 0.8736 - val_accuracy: 0.7795\n","Epoch 97/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.1627 - accuracy: 0.9429 - val_loss: 0.8858 - val_accuracy: 0.7795\n","Epoch 98/100\n","782/782 [==============================] - 29s 38ms/step - loss: 0.1624 - accuracy: 0.9432 - val_loss: 0.8911 - val_accuracy: 0.7724\n","Epoch 99/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1562 - accuracy: 0.9468 - val_loss: 0.8665 - val_accuracy: 0.7836\n","Epoch 100/100\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1535 - accuracy: 0.9471 - val_loss: 0.9003 - val_accuracy: 0.7820\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mh_E4wYagihs"},"source":["model.metrics_names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DS5QykzdX_yc"},"source":["# summarize history for accuracy\n","from matplotlib import pyplot as plt\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xbY7NhvGVGaM"},"source":["checkpoint.save('/content/drive/MyDrive/Colab Notebooks/2021/paper/CBAM_GhostNet/weightmodel.ckpt')"],"execution_count":null,"outputs":[]}]}